<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
	<style>
		body {
			background-color: #404040;
			background-color: white;
			padding: 100px;
			width: 1000px;
			margin: auto;
			text-align: left;
			font-weight: 300;
			font-family: "Open Sans", sans-serif;
			color: #121212;
		}

		h1,
		h2,
		h3,
		h4 {
			font-family: "Source Sans Pro", sans-serif;
		}

		kbd {
			color: #121212;
		}

		blockquote {
			color: #888;
			border: 2px solid #333;
			padding: 10px;
			background-color: #ccc;
		}

		table.custom-tbl {
			border: 1px solid;
		}

		table.custom-tbl th {
			border: 1px solid;
			background-color: rgb(99, 209, 209);
		}

		table.custom-tbl td {
			border: 1px solid;
			background-color: #f1e686a8;
		}

		/* The alert message box */
		.alert {
			padding: 20px;
			background-color: #f44336;
			/* Red */
			color: white;
			margin-bottom: 15px;
		}

		/* The close button */
		.closebtn {
			margin-left: 15px;
			color: white;
			font-weight: bold;
			float: right;
			font-size: 22px;
			line-height: 20px;
			cursor: pointer;
			transition: 0.3s;
		}

		/* When moving the mouse over the close button */
		.closebtn:hover {
			color: black;
		}
	</style>

	<title>CS 184 Meshes</title>
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<!-- Not using below due to lacking bold fontfaces -->
	<!-- <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro|Source+Sans+Pro:400,700" rel="stylesheet"> -->
	<link href="https://fonts.googleapis.com/css?family=Roboto+Mono|Roboto+Slab|Roboto:300,400,500,700"
		rel="stylesheet" />

	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
	</script>
</head>

<body style="padding-top: 50px">
	<!-- <div align="middle">
      <img
        src="https://drive.google.com/uc?id=1DZQwwl_aq1IEPGaZFk4bAYzEJNrqHRN4"
        align="middle"
        width="1000vw"
      />
    </div> -->

	<h1 align="left">CS 184: Computer Graphics and Imaging, Spring 2024</h1>
	<h1 align="left">Homework 3: Path Tracer</h1>
	<h2 align="left">Ecuas S'ojog: Bill Shao, Jonathan Pei</h2>
	<h3 align="left">Webpage Link: <a
			href="https://cal-cs184-student.github.io/hw-webpages-sp24-jonnypei/hw3/index.html">https://cal-cs184-student.github.io/hw-webpages-sp24-jonnypei/hw3/index.html</a>
		</h2>
		<hr />

	<h2 align="left">Overview</h2>
	<p>
	</p>

	<hr />
	<h2 align="middle">Part 1: Ray Generation and Scene Intersection</h1>
	<hr />

	<p>
		<b>Ray Generation Process:</b> the <code> generate_ray</code> function in camera.cpp works by 
		first converting the image point to camera space, then generating a cooresponding ray in world space.
		The image point is converted to camera space with the following code. 
		<pre>
auto new_x = (x - 0.5) * 2 * tan(hFov * M_PI / 360);
auto new_y = (y - 0.5) * 2 * tan(vFov * M_PI / 360);
auto point = Vector3D(new_x, new_y, -1);
		</pre>

		The <code> new_x, new_y </code> were rescaled to fit in the new range \( [-tan(fov/2), tan(fov/2)]  \) 
		and the z-coord was chosen as -1 since the image plane is defined as being aligned at z = -1.

		Finally, the ray endpoint and origin were converted to world space using the <code>c2w</code> transformation matrix, which results in the final generated ray.

		<br>
		<br>
		<b> Triangle Intersection:</b>  Triangle intersection was implemented using MÃ¶ller - Trumbore intersection. <br>

		<pre>
Vector3D edge1 = p2 - p1;
Vector3D edge2 = p3 - p1;

auto s1 = cross(r.d, edge2);
auto frac = dot(s1,edge1);

if (frac > -EPS_D && frac < EPS_D) {
    return false;
}
		</pre>

		This section sets up the variables \( E_1, E_2, S_1 \) and checks that \( S_1 \) is non-zero so the inverse is defined. This code also checks that the ray is not parallel to the triangle plane.
		
		<pre>
auto inv_det = 1.0 / frac;

auto s = r.o - p1;
double b2 = inv_det * dot(s, s1);

if (b2 < 0 || b2 > 1) {
    return false;
}

auto s2 = cross(s, edge1);
double b1 = inv_det * dot(s2,r.d);

if (b1 < 0 || b1 > 1 || b1+b2 > 1) {
    return false;
}

double t = inv_det * dot(edge2, s2);
		</pre>
		This section calculates the barycentric coordinate values \( b_1, b_2\), and returns the value of \(t\) cooresponding to the intersection point. 
		
		<pre>
isect->n = (1 - b1 - b2) * n1 + b2 * n2 + b1 * n3;
		</pre>

		Finally, the barycentric points are then used to fine the intersecion plane normal, which is shown above. <br> <br>

		<b> Sphere Intersection: </b> Sphere intersection was implemented as described in lecture by using the quadratic formula.
		<pre>
auto a = dot(r.d, r.d);
auto b = 2.0 * dot(r.o - this->o, r.d);
auto c = dot(r.o - this->o, r.o - this->o) - this->r2;

if (b * b - 4.0 * a * c < 0) {
    return false;
}

t1 = (-b - sqrt(b * b - 4 * a * c)) / (2 * a);
t2 = (-b + sqrt(b * b - 4 * a * c)) / (2 * a);
		</pre>
		a,b, and c are calculated using the method on lecture slides, and a preliminary check is done to make sure the value of t being found is real, otherwise the intersection doesn't exist. 
		Once this is done, both intersection points <code>t1, t2</code> are found and the smallest is returned as the <code>t</code> parameter cooresponding to the sphere-ray intersection point. The <code>r.max_t</code> 
		parameter is also set here so that only the closest intersection is considered. 
		<br><br>
		Finally, the following code finds the normal vector of the intersection, which works by finding the direction from origin to intersect point and then normalizing it.

		<pre>
auto normvec = ((r.o + r.d * i->t) - this->o);
normvec.normalize();
		</pre>
		
		<p><b>Normal Shading on Small <code>.dae</code> Files:</b></p>
	</p>

	<div align="middle">
		<table style="width: 100%">
		  <tr align="center">
			<td>
			  <img src="images/normalshading1.png" align="middle" width="400vw" />
			  <figcaption>Example of normal shading on <code>CBspheres.dae</code>. </figcaption>
			</td>
			<td>
			  <img src="images/normalshading2.png" align="middle" width="400vw" />
			  <figcaption>Example of normal shading on <code>CBgems.dae</code>. </figcaption>
			</td>
		</table>
	  </div>

	<hr />
	<h2 align="middle">Part 2: Bounding Volume Hierarchy</h1>
	<hr />

	<p><b>BVH Construction Algorithm:</b> we build up the BVH by recursively splitting the primitives based on a heuristic on the dimensions of the bounding centroid box. Its structure is described below:</p>
	<ol>
		<li><b>Create a new node:</b> <code>BVHNode *node = new BVHNode(bbox);</code></li>
		<li><b>Base Case:</b> if the number of primitives is less than or equal to the max leaf size, then we simply set the start and end pointers for the primitive list.</li>
		<pre>
if (num_prim <= max_leaf_size) {
    node->start = start;
    node->end = end;
}
</pre>
<li><b>Recursive Case:</b> we split the primitives (based on a heuristic) among the two children of the created <code>BVHNode</code>. We describe our heuristic in the next section.</li>
		<li><b>Return the node.</b></li>
	</ol>
	<p><b>BVH Splitting Heuristic:</b> we split the primitives based on the centroid of the centroid bounding box. Specifically, we compare a primitive's centroid with that of the centroid bounding box, along the largest dimension of the centroid bounding box. We provide code implementations below:</p>

	<ol>
		<li><b>Computation of centroid bounding box:</b>
			<pre>
BBox bbox, centroid_box;

for (auto p = start; p != end; p++) {
    BBox bb = (*p)->get_bbox();
    bbox.expand(bb);
    centroid_box.expand(bb.centroid());
}

// At this point, centroid_box contains the centroids of all bounding boxes
			</pre>
		</li>
		<li><b>Splitting operation:</b>
			<pre>
int axis = maxDimension(centroid_box.extent);

// Compute left and right sides
std::vector<Primitive *> prims_l;
std::vector<Primitive *> prims_r;
for (auto p = start; p != end; p++) {
    if ((*p)->get_bbox().centroid()[axis] >= centroid_box.centroid()[axis]) {
	prims_l.push_back(*p);
    } else {
	prims_r.push_back(*p);
    }
}

// Compute split pointer
auto split = start + prims_l.size();

// Move the objects into positions
for (int i = 0; i < num_prim; i++) {
    if (i < prims_l.size()) {
	*(start + i) = prims_l[i];
    } else {
	*(start + i) = prims_r[i - prims_l.size()];
    }
}

node->l = construct_bvh(start, split, max_leaf_size);
node->r = construct_bvh(split, end, max_leaf_size);
			</pre>
		</li>
	</ol>

	<p><b>Normal Shading on Large <code>.dae</code> Files:</b></p>

	<div align="middle">
		<table style="width: 100%">
		  <tr align="center">
			<td>
			  <img src="images/p2_blob.png" align="middle" width="300vw" />
			  <figcaption>Example of normal shading on <code>blob.dae</code>.</figcaption>
			</td>
			<td>
				<img src="images/p2_CBlucy.png" align="middle" width="300vw" />
				<figcaption>Example of normal shading on <code>CBlucy.dae</code>.</figcaption>
			</td>
			<td>
				<img src="images/p2_dragon.png" align="middle" width="300vw" />
				<figcaption>Example of normal shading on <code>dragon.dae</code>.</figcaption>
			</td>
		  </tr>
		</table>
	  </div>
	
	  <p><b>With vs. Without BVH Acceleration:</b> we observed substantial speedups on rendering times, displayed in the table below. We found empirical evidence supporting the asymptotic speedup of BVH, as the rendering time seems to go from approximately linear to logarithmic with respect to the number of primitives. An interesting result is that <code>CBlucy.dae</code> took the least time to render, despite it being the most geometrically complex; we believe that this is due to the scene's small triangles, which are rendered quickly via BVH. 
	
	  <div align="middle">
		<table style="width: 100%">
		  <tr align="center">
			<td>
			  <img src="images/p2_comparison_table.png" align="middle" width="800vw" />
			  <figcaption>Comparison Table of Renders Without and With BVH Acceleration.</figcaption>
			</td>
		  </tr>
		</table>
	  </div>



	  <hr />
	<h2 align="middle">Part 3: Direct Illumination</h1>
	<hr />

	<p><b>estimate_direct_lighting_hemisphere: </b> Uniform hemisphere sampling works by taking an intersection 
		point to analyze the lighting of and then taking random samples across a hemisphere in order to determine
		 its light level. First, after determinining the <code>hit_p</code> of the intersection, a randomly sampled ray is generated at that location, 
		 taking note that it is in object space and needs to be coverted with <code>o2w</code>. <code>EPS_F</code> is set here so the intersecting place is at least some distance away from the ray.

		 <pre>
auto samplevec = hemisphereSampler->get_sample(); 
Ray r_sample = Ray(hit_p, (o2w * samplevec).unit());
r_sample.min_t = EPS_F; //for super close collision purposes
		 </pre>
		
		 After this, <code>r_sample</code> is passed through an intersection test and the intersect point's emmission is then added to the sampler
		 using the reflection equation in lecture. The value for <code>cosj</code> was derived based on the original idea of how the image plane is represented in world space.
		  

		 <pre>
Intersection intersecttest;

if (bvh->intersect(r_sample, &intersecttest)) {
    auto cosj = dot(samplevec, Vector3D(0, 0, 1));
    auto sample = isect.bsdf->f(w_out, samplevec) * intersecttest.bsdf->get_emission() * cosj;
    auto pdf = 1 / (2 * PI);

    radianceSampler += sample / pdf;
}
		 </pre>

		 Finally, radianceSampler is normalized over samples taken and returned.
		 
		 <pre>
return radianceSampler / num_samples;
		 </pre>

		<div align="middle">
			<table style="width: 100%">
			  <tr align="center">
				<td>
				  <img src="images/CBbunny_H_16_8.png" align="middle" width="500vw" />
				  <figcaption><code>CBbunny.dae</code> with uniform hemisphere sampling (<code>s=16</code>, <code>l=8</code>).</figcaption>
				</td>
			  </tr>
			</table>
		  </div>
		<b>estimate_direct_lighting_importance: </b> Importance sampling follows the same approach as uniform sampling, with a few modifications. Instead of sampling uniformly over a hemisphere, we sample uniformly from each light source and only consider rays that hit the intersection points. In particular, for a given pixel, we sample one ray from each point source, and <code>ns_area_light</code> samples from each area source. The algorithm also makes sure to reject "shadow rays" that are on the opposite side of the incoming ray (with respect to the reflection surface).
		See below for our code implementation:
		<pre>
for (auto light = scene->lights.begin(); light != scene->lights.end(); light++) {
    Vector3D wi;
    double distToLight;
    double pdf;

    Vector3D L;
    Vector3D L_total = Vector3D();
    int num_samples = 0;

    for (int i = 0; i < ns_area_light; i++) {
	auto L = (*light)->sample_L(hit_p, &wi, &distToLight, &pdf);
	auto cosj = dot(wi, isect.n);

	Ray r_sample = Ray(hit_p, wi);
	r_sample.min_t = EPS_F;
	r_sample.max_t = distToLight - EPS_F;
	Intersection next_isect;

	if (cosj > 0 && distToLight > 0 && !(bvh->intersect(r_sample, &next_isect))) {
	    auto sample = isect.bsdf->f(w_out, wi) * L * cosj;
	
	    L_total += sample / pdf;
	}
	num_samples++;
	
	if ((*light)->is_delta_light()) {
	    break;
	}
    }
    L_out += L_total / num_samples;
}
	
return L_out;
		</pre>
		<div align="middle">
			<table style="width: 100%">
			  <tr align="center">
				<td>
				  <img src="images/CBbunny_H_16_8 copy.png" align="middle" width="500vw" />
				  <figcaption><code>CBbunny.dae</code> with importance sampling (<code>s=16</code>, <code>l=8</code>).</figcaption>
				</td>
			  </tr>
			</table>
		  </div>
	
		  <b>Noise Level Comparison of <code>CBspheres_lambdarian.dae</code>: </b>

		  <div align="middle">
			<table style="width: 100%">
			  <tr align="center">
				<td>
				  <img src="images/blob1.png" align="middle" width="200vw" />
				  <figcaption><code>l=1</code></figcaption>
				</td>
				<td>
					<img src="images/blob4.png" align="middle" width="200vw" />
					<figcaption><code>l=4</code></figcaption>
				</td>
				<td>
					<img src="images/blob16.png" align="middle" width="200vw" />
					<figcaption><code>l=16</code></figcaption>
				</td>
				<td>
					<img src="images/blob64.png" align="middle" width="200vw" />
					<figcaption><code>l=64</code></figcaption>
				</td>  
			  </tr>
			</table>
		  </div>
		  <br>

		  Here, it is clear that the noise drastically reduces and the number of samples taken per light source increases. Which makes sense since the random samples will converge to their true values better over the course of many samples. 
		  It is also important to note that the starting render at <code>l=1</code> performs quite well still, due to the use of lighting sampling rather than random sampling. 
		  <br> <br>

		  <b>Uniform vs Importance Sampling: </b> <br>
		  As generally expected, the noise when performing importance sampling is drastically lower than when performing uniform hemisphere 
		  sampling. This can be noticed in the CBbunny.dae renders above with (<code>s=16</code>, <code>l=8</code>). Even though both renders have the same number of samples, the 
		  use of importance sampling allows for the pixel to converge to the true luminance much quicker, and reduces the pixelated variance present. Another
		  interesting comparision can be seen below.
		
		  <div align="middle">
			<table style="width: 100%">
			  <tr align="center">
				<td>
				  <img src="images/bunny_1_1.png" align="middle" width="500vw" />
				  <figcaption><code>CBbunny.dae</code> with importance sampling (<code>s=1</code>, <code>l=1</code>).</figcaption>
				</td>
			  </tr>
			</table>
		  </div>
		  Here, only 1 sample was taken per pixel per light, allowing it to converge and finish rendering much faster than the two methods described above.
		  Even though this is the case, the image has comparable quality to the uniform hemisphere sample, which uses many more samples. This means that important sampling 
		  is a useful optimization to improve picture quality as well as render similar quality pictures with less computations.
		</p>
		  <p>
		  In a nut shell, importance sampling "limits" the uniform hemisphere sampling to focus only on rays originating from light sources, which allows it to sample both more efficiently and effectively (i.e. more accurate colors). Furthermore, importance sampling is much more effective at rendering point light sources, as uniform sampling has a very low probability of sampling the exact point source ray. 
	</p>

	<hr />
	<h2 align="middle">Part 4: Global Illumination</h1>
	<hr />

	<p><b>Global Illumination Implementation:</b> the crux of global lighting in <code>at_least_one_bounce_radiance()</code> is the added support of indirect lighting, in which we accumulate radiance from multiple bounces of light. Our implementation consists of the following steps:</p>
	<ol>
		<li>Initialize the radiance of <code>L_out</code> to include direct illumination via <code>one_bounce_radiance()</code>.</li>
		<li>If the ray's depth (originally <code>max_ray_depth</code>) is less than or equal to 1, we terminate and return <code>L_out</code>.</li>
		<li>If using Russian Roulette, we terminate and return <code>L_out</code> with a certain termination probability. We chose a reasonable termination probability of 0.4.</li>
		<li>If we don't terminate, then we cast the next "bounce" of the ray <code>next_r</code> by sampling a direction from the BSDF via <code>isect.bsdf->sample_f()</code>, with decremented depth <code>r.depth - 1</code>.</li>
		<li>If <code>next_r</code> intersects the <code>bvh</code>, we compute its radiance by recursively calling <code>at_least_one_bounce_radiance</code> on it. Then, we accumulate this indirect (via bouncing) light by scaling it with the current intersection reflectance (from step 4) and the direction of <code>next_r</code>. Finally, we make sure to divide by the BSDF sample pdf and, if applicable, the Russian Roulette continuation probability.</li>
	</ol>

	<p><b>Example Renderings with Global Illumination:</b> we provide a couple example images rendered with global (direct and indirect) illumination, using 1024 samples per pixel:</p>

	<div align="middle">
		<table style="width: 100%">
		  <tr align="center">
			<td>
			  <img src="images/p4_ex_bunny.png" align="middle" width="400vw" />
			  <figcaption><code>CBbunny.dae</code></figcaption>
			</td>
			<td>
			  <img src="images/p4_ex_banana.png" align="middle" width="400vw" />
			  <figcaption><code>banana.dae</code></figcaption>
			</td>
			<!-- <td>
			  <img src="images/p4_ex_walle.png" align="middle" width="300vw" />
			  <figcaption><code>wall-e.dae</code></figcaption>
			</td> -->
		</table>
	  </div>

	<p><b>Visualizing Direct vs. Indirect Illumination:</b> to visualize the separate contributions of direct and indirect lighting to global illumination, we provide renderings of <code>CBspheres_lambertian.dae</code> with only direct illumination (left) and only indirect illumination (right). Both renders use 1024 samples per pixel, 16 samples per area light, and a max ray depth of 5.</p>

	<div align="middle">
		<table style="width: 100%">
		  <tr align="center">
			<td>
			  <img src="images/p4_cbspheres_direct.png" align="middle" width="400vw" />
			  <figcaption>Rendering of <code>CBspheres_lambertian.dae</code> with only <b>direct</b> lighting. </figcaption>
			</td>
			<td>
			  <img src="images/p4_cbspheres_indirect.png" align="middle" width="400vw" />
			  <figcaption>Rendering of <code>CBspheres_lambertian.dae</code> with only <b>indirect</b> lighting. </figcaption>
			</td>
		</table>
	  </div>
	<p>
	Notice that parts of the scene that could only be lit by indirect light bounces (e.g. the ceiling and bottoms of the spheres) are lit up in the indirect rendering.
</p>

<p><b>Rendering Light Bounces:</b> we provide rendered views of <code>CBbunny.dae</code> with <code>max_ray_depth</code> set to 0, 1, 2, 3, 4, and 5, while varying <code>isAccumBounces</code>. Here, we aim to visualize how each successive light bounce behaves and contributes to the global illumination. All renders below use 1024 samples per pixel and 32 samples per area light. </p>

<p><code>isAccumBounces=false</code> (i.e. individual bounce):</p>
<div align="middle">
	<table style="width: 100%">
	  <tr align="center">
		<td>
		  <img src="images/CBbunny_nobounce_m0.png" align="middle" width="150vw" />
		  <figcaption><code>m=0</code></figcaption>
		</td>
		<td>
			<img src="images/CBbunny_nobounce_m1.png" align="middle" width="150vw" />
			<figcaption><code>m=1</code></figcaption>
		  </td>
		  <td>
			<img src="images/CBbunny_nobounce_m2.png" align="middle" width="150vw" />
			<figcaption><code>m=2</code></figcaption>
		  </td>
		  <td>
			<img src="images/CBbunny_nobounce_m2.png" align="middle" width="150vw" />
			<figcaption><code>m=2</code></figcaption>
		  </td>
		  <td>
			<img src="images/CBbunny_nobounce_m3.png" align="middle" width="150vw" />
			<figcaption><code>m=3</code></figcaption>
		  </td>
		  <td>
			<img src="images/CBbunny_nobounce_m4.png" align="middle" width="150vw" />
			<figcaption><code>m=4</code></figcaption>
		  </td>
		  <td>
			<img src="images/CBbunny_nobounce_m5.png" align="middle" width="150vw" />
			<figcaption><code>m=5</code></figcaption>
		  </td>
	</table>
  </div>

  <p><code>isAccumBounces=true</code> (i.e. accumulates bounces):</p>
  <div align="middle">
	<table style="width: 100%">
	  <tr align="center">
		<td>
		  <img src="images/CBbunny_bounce_m0.png" align="middle" width="150vw" />
		  <figcaption><code>m=0</code></figcaption>
		</td>
		<td>
			<img src="images/CBbunny_bounce_m1.png" align="middle" width="150vw" />
			<figcaption><code>m=1</code></figcaption>
		  </td>
		  <td>
			<img src="images/CBbunny_bounce_m2.png" align="middle" width="150vw" />
			<figcaption><code>m=2</code></figcaption>
		  </td>
		  <td>
			<img src="images/CBbunny_bounce_m2.png" align="middle" width="150vw" />
			<figcaption><code>m=2</code></figcaption>
		  </td>
		  <td>
			<img src="images/CBbunny_bounce_m3.png" align="middle" width="150vw" />
			<figcaption><code>m=3</code></figcaption>
		  </td>
		  <td>
			<img src="images/CBbunny_bounce_m4.png" align="middle" width="150vw" />
			<figcaption><code>m=4</code></figcaption>
		  </td>
		  <td>
			<img src="images/CBbunny_bounce_m5.png" align="middle" width="150vw" />
			<figcaption><code>m=5</code></figcaption>
		  </td>
	</table>
  </div>
<p><b>Global Illumination with Russian Roulette:</b> we now display renderings of <code>CBbunny.dae</code> using Russian Roulette, with <code>max_ray_depth</code> set to 0, 1, 2, 3, 4, and 5. All renders below use 1024 samples per pixel and 32 samples per area light.</p>

<div align="middle">
	<table style="width: 100%">
	  <tr align="center">
		<td>
		  <img src="images/CBbunny_rr_m0.png" align="middle" width="150vw" />
		  <figcaption><code>m=0</code></figcaption>
		</td>
		<td>
			<img src="images/CBbunny_rr_m1.png" align="middle" width="150vw" />
			<figcaption><code>m=1</code></figcaption>
		  </td>
		  <td>
			<img src="images/CBbunny_rr_m2.png" align="middle" width="150vw" />
			<figcaption><code>m=2</code></figcaption>
		  </td>
		  <td>
			<img src="images/CBbunny_rr_m2.png" align="middle" width="150vw" />
			<figcaption><code>m=2</code></figcaption>
		  </td>
		  <td>
			<img src="images/CBbunny_rr_m3.png" align="middle" width="150vw" />
			<figcaption><code>m=3</code></figcaption>
		  </td>
		  <td>
			<img src="images/CBbunny_rr_m4.png" align="middle" width="150vw" />
			<figcaption><code>m=4</code></figcaption>
		  </td>
		  <td>
			<img src="images/CBbunny_rr_m5.png" align="middle" width="150vw" />
			<figcaption><code>m=5</code></figcaption>
		  </td>
	</table>
  </div>

<p><b>Varying Sample-per-Pixel:</b> we display rendered views of <code>CBdragon.dae</code> with sample-per-pixel rates of 1, 2, 4, 8, 16, 64, and 1024. All renders below use 16 samples per area light, and a max ray depth of 4.</p>

<div align="middle">
	<table style="width: 100%">
	  <tr align="center">
		<td>
		  <img src="images/dragon_s1_rate.png" align="middle" width="150vw" />
		  <figcaption><code>s=1</code></figcaption>
		</td>
		<td>
			<img src="images/dragon_s2_rate.png" align="middle" width="150vw" />
			<figcaption><code>s=2</code></figcaption>
		  </td>
		  <td>
			<img src="images/dragon_s4_rate.png" align="middle" width="150vw" />
			<figcaption><code>s=4</code></figcaption>
		  </td>
		  <td>
			<img src="images/dragon_s8_rate.png" align="middle" width="150vw" />
			<figcaption><code>s=8</code></figcaption>
		  </td>
		  <td>
			<img src="images/dragon_s16_rate.png" align="middle" width="150vw" />
			<figcaption><code>s=16</code></figcaption>
		  </td>
		  <td>
			<img src="images/dragon_s64_rate.png" align="middle" width="150vw" />
			<figcaption><code>s=64</code></figcaption>
		  </td>
		  <td>
			<img src="images/dragon_s1024_rate.png" align="middle" width="150vw" />
			<figcaption><code>s=1024</code></figcaption>
		  </td>
	</table>
  </div>

<hr />
	<h2 align="middle">Part 5: Adaptive Sampling</h1>
	<hr />

	<p><b>How does Adaptive Sampling work: </b>Adaptive Sampling works by creating a distribution
     based on the sample rays collected so far, and terminates when the sampled result 
     is most likely correct based on that distribution. In our implementation, being likely correct means being 95% confident that 
    the sampled illuminance is within \( maxTolerance \cdot \mu \) away. The values \( \mu\) and \( \sigma^2 \)are calculated based on an accumulating total and checked every samplesPerBatch iterations. <br>
	</p>
	<p>	
	<b>Adaptive Sampling Implementation: </b>
		
		<pre>
double sample_illum = sample_radiance.illum();

s1 += sample_illum;
s2 += sample_illum * sample_illum;
batch_size++;

// adaptive sampling
if (batch_size % samplesPerBatch == 0) {
    auto mu = s1 / n;
    auto var = (1.0 / (n - 1)) * (s2 - (s1 * s1) / n);
    auto I2 = 1.96 * 1.96 * var / n;
    auto cutoff2 = maxTolerance * maxTolerance * mu * mu;
	
    if (I2 <= cutoff2) {
	break;
    }
}
		</pre>

		In our implementation, rather than compute <code>I</code> and <code>cutoff</code> directly, we just calcuate the squared versions and compare those to avoid using <code>sqrt</code>. 
		We also check for termination whenever <code> batch_size % samplesPerBatch == 0 </code>, and calculates the equation presented in the spec. 


	</p>

	<div align="middle">
		<table style="width: 100%">
		  <tr align="center">
			<td>
			  <img src="images/bunny.png" align="middle" width="400vw" />
			  <figcaption><code>CBbunny.dae</code> noise free rendered result. </figcaption>
			</td>
			<td>
			  <img src="images/bunny_rate.png" align="middle" width="400vw" />
			  <figcaption><code>CBbunny.dae</code> heatmap showing samples taken per pixel. </figcaption>
			</td>
		</table>
	  </div>

</html>