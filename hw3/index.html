<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
	<style>
		body {
			background-color: #404040;
			background-color: white;
			padding: 100px;
			width: 1000px;
			margin: auto;
			text-align: left;
			font-weight: 300;
			font-family: "Open Sans", sans-serif;
			color: #121212;
		}

		h1,
		h2,
		h3,
		h4 {
			font-family: "Source Sans Pro", sans-serif;
		}

		kbd {
			color: #121212;
		}

		blockquote {
			color: #888;
			border: 2px solid #333;
			padding: 10px;
			background-color: #ccc;
		}

		table.custom-tbl {
			border: 1px solid;
		}

		table.custom-tbl th {
			border: 1px solid;
			background-color: rgb(99, 209, 209);
		}

		table.custom-tbl td {
			border: 1px solid;
			background-color: #f1e686a8;
		}

		/* The alert message box */
		.alert {
			padding: 20px;
			background-color: #f44336;
			/* Red */
			color: white;
			margin-bottom: 15px;
		}

		/* The close button */
		.closebtn {
			margin-left: 15px;
			color: white;
			font-weight: bold;
			float: right;
			font-size: 22px;
			line-height: 20px;
			cursor: pointer;
			transition: 0.3s;
		}

		/* When moving the mouse over the close button */
		.closebtn:hover {
			color: black;
		}
	</style>

	<title>CS 184 Meshes</title>
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<!-- Not using below due to lacking bold fontfaces -->
	<!-- <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro|Source+Sans+Pro:400,700" rel="stylesheet"> -->
	<link href="https://fonts.googleapis.com/css?family=Roboto+Mono|Roboto+Slab|Roboto:300,400,500,700"
		rel="stylesheet" />

	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
	</script>
</head>

<body style="padding-top: 50px">
	<!-- <div align="middle">
      <img
        src="https://drive.google.com/uc?id=1DZQwwl_aq1IEPGaZFk4bAYzEJNrqHRN4"
        align="middle"
        width="1000vw"
      />
    </div> -->

	<h1 align="left">CS 184: Computer Graphics and Imaging, Spring 2024</h1>
	<h1 align="left">Homework 3: Path Tracer</h1>
	<h2 align="left">Ecuas S'ojog: Bill Shao, Jonathan Pei</h2>
	<h3 align="left">Webpage Link: <a
			href="https://cal-cs184-student.github.io/hw-webpages-sp24-jonnypei/hw3/index.html">https://cal-cs184-student.github.io/hw-webpages-sp24-jonnypei/hw3/index.html</a>
		</h2>
		<hr />

	<h2 align="left">Overview</h2>
	<p>
	</p>

	<hr />
	<h2 align="middle">Part 1: Ray Generation and Scene Intersection</h1>
	<hr />

	<p>
		<b>Ray Generation Process:</b> the <code> generate_ray</code> function in camera.cpp works by 
		first converting the image point to camera space, then generating a cooresponding ray in world space.
		The image point is converted to camera space with the following code. 
		<pre>
			auto new_x = (x - 0.5) * 2 * tan(hFov * M_PI / 360);
			auto new_y = (y - 0.5) * 2 * tan(vFov * M_PI / 360);
			auto point = Vector3D(new_x, new_y, -1);
		</pre>

		The <code> new_x, new_y </code> were rescaled to fit in the new range \( [-tan(fov/2), tan(fov/2)]  \) 
		and the z-coord was chosen as -1 since the image plane is defined as being aligned at z = -1.

		Finally, the ray endpoint and origin were converted to world space using the <code>c2w</code> transformation matrix, which results in the final generated ray.

		<br>
		<br>
		<b> Triangle Intersection:</b>  Triangle intersection was implemented using MÃ¶ller - Trumbore intersection. <br>

		<pre>
			Vector3D edge1 = p2 - p1;
			Vector3D edge2 = p3 - p1;

			auto s1 = cross(r.d, edge2);
			auto frac = dot(s1,edge1);

			if (frac > -EPS_D && frac < EPS_D) {
				return false;
			}
		</pre>

		This section sets up the variables \( E_1, E_2, S_1 \) and checks that \( S_1 \) is non-zero so the inverse is defined. This code also checks that the ray is not parallel to the triangle plane.
		
		<pre>

			auto inv_det = 1.0 / frac;

			auto s = r.o - p1;
			double b2 = inv_det * dot(s, s1);

			if (b2 < 0 || b2 > 1) {
				return false;
			}

			auto s2 = cross(s, edge1);
			double b1 = inv_det * dot(s2,r.d);

			if (b1 < 0 || b1 > 1 || b1+b2 > 1) {
				return false;
			}

			double t = inv_det * dot(edge2, s2);
		</pre>
		This section calculates the barycentric coordinate values \( b_1, b_2\), and returns the value of \(t\) cooresponding to the intersection point. 
		
		<pre>
			isect->n = (1 - b1 - b2) * n1 + b2 * n2 + b1 * n3;
		</pre>

		Finally, the barycentric points are then used to fine the intersecion plane normal, which is shown above. <br> <br>

		<b> Sphere Intersection: </b> Sphere intersection was implemented as described in lecture by using the quadratic formula.
		<pre>
			auto a = dot(r.d, r.d);
			auto b = 2.0 * dot(r.o - this->o, r.d);
			auto c = dot(r.o - this->o, r.o - this->o) - this->r2;

			if (b * b - 4.0 * a * c < 0) {
				return false;
			}

			t1 = (-b - sqrt(b * b - 4 * a * c)) / (2 * a);
			t2 = (-b + sqrt(b * b - 4 * a * c)) / (2 * a);
		</pre>
		a,b, and c are calculated using the method on lecture slides, and a preliminary check is done to make sure the value of t being found is real, otherwise the intersection doesn't exist. 
		Once this is done, both intersection points <code>t1, t2</code> are found and the smallest is returned as the <code>t</code> parameter cooresponding to the sphere-ray intersection point. The <code>r.max_t</code> 
		parameter is also set here so that only the closest intersection is considered. 
		<br><br>
		Finally, the following code finds the normal vector of the intersection, which works by finding the direction from origin to intersect point and then normalizing it.

		<pre>
			auto normvec = ((r.o + r.d * i->t) - this->o);
			normvec.normalize();

		</pre>
		
		<br>


	
	
	
	
	</p>

	<div align="middle">
		<table style="width: 100%">
		  <tr align="center">
			<td>
			  <img src="images/normalshading1.png" align="middle" width="500vw" />
			  <figcaption>Example of normal shading on CBspheres.dae. </figcaption>
			</td>
			<td>
			  <img src="images/normalshading2.png" align="middle" width="500vw" />
			  <figcaption>Example of normal shading on CBgems.dae. </figcaption>
			</td>
		</table>
	  </div>

	<hr />
	<h2 align="middle">Part 2: Bounding Volume Hierarchy</h1>
	<hr />

	<p>stuff</p>

	<hr />
	<h2 align="middle">Part 3: Direct Illumination</h1>
	<hr />

	<p><b>estimate_direct_lighting_hemisphere: </b> Uniform hemisphere sampling works by taking an intersection 
		point to analyze the lighting of and then taking random samples across a hemisphere in order to determine
		 its light level. First, after determinining the <code>hit_p</code> of the intersection, a randomly sampled ray is generated at that location, 
		 taking note that it is in object space and needs to be coverted with <code>o2w</code>. <code>EPS_F</code> is set here so the intersecting place is at least some distance away from the ray.

		 <pre>
			auto samplevec = hemisphereSampler->get_sample(); 
			Ray r_sample = Ray(hit_p, (o2w * samplevec).unit());
			r_sample.min_t = EPS_F; //for super close collision purposes
		 </pre>
		
		 After this, <code>r_sample</code> is passed through an intersection test and the intersect point's emmission is then added to the sampler
		 using the reflection equation in lecture. The value for <code>cosj</code> was derived based on the original idea of how the image plane is represented in world space.
		  

		 <pre>
			Intersection intersecttest;

			if (bvh->intersect(r_sample, &intersecttest)) {
			auto cosj = dot(samplevec, Vector3D(0, 0, 1));
			auto sample = isect.bsdf->f(w_out, samplevec) *
							intersecttest.bsdf->get_emission() * cosj;
			auto pdf = 1 / (2 * PI);

			radianceSampler += sample / pdf;
			}
		 </pre>

		 Finally, radianceSampler is normalized over samples taken and returned.
		 
		 <pre>
			return radianceSampler / num_samples;
		 </pre>
		 



		<div align="middle">
			<table style="width: 100%">
			  <tr align="center">
				<td>
				  <img src="images/CBbunny_H_16_8.png" align="middle" width="300vw" />
				  <figcaption>CBbunny.dae with uniform hemisphere sampling (s = 16, l = 8).</figcaption>
				</td>
			  </tr>
			</table>
		  </div>
		<b>estimate_direct_lighting_importance: </b> 

		TODO


		<div align="middle">
			<table style="width: 100%">
			  <tr align="center">
				<td>
				  <img src="images/CBbunny_H_16_8 copy.png" align="middle" width="300vw" />
				  <figcaption>CBbunny.dae with importance sampling (s = 16, l = 8).</figcaption>
				</td>
			  </tr>
			</table>
		  </div>
	
		  <b>Noise Level Comparision: </b>

		  <div align="middle">
			<table style="width: 100%">
			  <tr align="center">
				<td>
				  <img src="images/blob1.png" align="middle" width="300vw" />
				  <figcaption>CBspheres_lambdarian.dae with l=1.</figcaption>
				</td>
				<td>
					<img src="images/blob4.png" align="middle" width="300vw" />
					<figcaption>CBspheres_lambdarian.dae with l=4.</figcaption>
				</td>
				<td>
					<img src="images/blob16.png" align="middle" width="300vw" />
					<figcaption>CBspheres_lambdarian.dae with l=16.</figcaption>
				</td>
				<td>
					<img src="images/blob64.png" align="middle" width="300vw" />
					<figcaption>CBspheres_lambdarian.dae with l=64.</figcaption>
				</td>  
			  </tr>
			</table>
		  </div>
		  <br>

		  Here, it is clear that the noise drastically reduces and the number of samples taken per light source increases. Which makes sense since the random samples will converge to their true values better over the course of many samples. 
		  It is also important to note that the starting render at l=1 performs quite well still, due to the use of lighting sampling rather than random sampling. 
		  <br> <br>

		  <b>Uniform vs Importance Sampling: </b> <br>
		  As generally expected, the noise when performing importance sampling is drastically lower than when performing uniform hemisphere 
		  sampling. This can be noticed in the CBbunny.dae renders above with (s=16, l=8). Even though both renders have the same number of samples, the 
		  use of importance sampling allows for the pixel to converge to the true luminance much quicker, and reduces the pixelated variance present. Another
		  interesting comparision can be seen below.
		
		  <div align="middle">
			<table style="width: 100%">
			  <tr align="center">
				<td>
				  <img src="images/bunny_1_1.png" align="middle" width="300vw" />
				  <figcaption>CBbunny.dae with importance sampling (s = 1, l = 1).</figcaption>
				</td>
			  </tr>
			</table>
		  </div>
		  Here, only 1 sample was taken per pixel per light, allowing it to converge and finish rendering much faster than the two methods described above.
		  Even though this is the case, the image has comparable quality to the uniform hemisphere sample, which uses many more samples. This means that important sampling 
		  is a useful optimization to improve picture quality as well as render similar quality pictures with less computations.  <b>TODO</b>
	
	</p>

	<hr />
	<h2 align="middle">Part 4: Global Illumination</h1>
	<hr />

	<p>stuff</p>

	<hr />
	<h2 align="middle">Part 5: Adaptive Sampling</h1>
	<hr />

	<p><b>How does Adaptive Sampling work: </b>Adaptive Sampling works by creating a distribution
     based on the sample rays collected so far, and terminates when the sampled result 
     is most likely correct based on that distribution. In our implementation, being likely correct means being 95% confident that 
    the sampled illuminance is within \( maxTolerance *  \mu \) away. The values \( \mu\) and \( \sigma^2 \)are calculated based on an accumulating total and checked every samplesPerBatch iterations. <br>
		<b>Adaptive Sampling Implementation: </b>
		
		<pre>
			double sample_illum = sample_radiance.illum();

			s1 += sample_illum;
			s2 += sample_illum * sample_illum;
			batch_size++;

    

			// adaptive sampling
			if (batch_size % samplesPerBatch == 0) {
			
				auto mu = s1 / n;
				auto var = (1.0 / (n - 1)) * (s2 - (s1 * s1) / n);
				auto I2 = 1.96 * 1.96 * var / n;
				auto cutoff2 = maxTolerance * maxTolerance * mu * mu;
				
				if (I2 <= cutoff2) {
					break;
				}
			}
		</pre>

		In our implementation, rather than compute <code>I</code> and <code>cutoff</code> directly, we just calcuate the squared versions and compare those to avoid using <code>sqrt</code>. 
		We also check for termination whenever <code> batch_size % samplesPerBatch == 0 </code>, and calculates the equation presented in the spec. 


	</p>

	<div align="middle">
		<table style="width: 100%">
		  <tr align="center">
			<td>
			  <img src="images/bunny.png" align="middle" width="500vw" />
			  <figcaption>CBBunny.dae noise free rendered result. </figcaption>
			</td>
			<td>
			  <img src="images/bunny_rate.png" align="middle" width="500vw" />
			  <figcaption>CBBunny.dae heatmap showing samples taken per pixel. </figcaption>
			</td>
		</table>
	  </div>

</html>